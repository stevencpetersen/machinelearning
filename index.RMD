---
title: "Barbell Lifting Mechanics Quality Prediction"
author: "Steven C. Petersen"
date: "Friday, August 22, 2014"
output: html_document
---

###Overview###

The purpose of this project is to select features and develop a model to predict the quality of barbell weight lifting based on data gathered in a previous project. Subjects were instructed to perform forearm curls in both correct and incorrect ways. Various measurements were take from devices attached to the participants and the dumbbells that measured a variety of mechanical and dimensional characteristics. This data is being utilized in this project and was obtained from this site which also describes the original study - http://groupware.les.inf.puc-rio.br/har. The goal is to perform pre-processing and model development to ultimately predict 20 test cases to be submitted for grading.

###Feature Selection & Pre-Processing###

Upon review of the test data, it is noted that all test examples contain a new_window value of "no", whereas the training data contains rows with new_window values of "yes". The important fact in this is that the rows with  new_window of "yes" also contain values in columns that appear to have meaningful values, whereas in the rows with new_window of "no", the same columns contain all "NA" values or are blank. It is assumed that model development  and training on the columns with values versus "NA" values will confound model development as these can not possibly contribute to predicting values on samples where these columns are "NA". Hence the rows with new_window of "yes" are removed from training set. Additionally, columns with 100% "NA" or blanks are assumed to contribute nothing to prediction, as they equally contain "NA" and blank values in the test set, and are therefore removed from both the training set and the test set.

Further the first 7 columns contain data with have no predictive value, i.e. subject name, date, time, etc. Considering that the positional data is key and might occur at any point and in any sequence these columns were also removed. This yielded 52 predictor variables and the response variables. All pre-processing was applied equally to the provided test set and to the training set. The training set was split into subsets for training and testing independent of the final test set to be used for grading.

Below the caret package is loaded, working directory set, training data loaded, rows with extraneous data (new_window "yes") are removed, columns containing only "NA" are removed, and columns containing only blanks are removed.

```{r}
library(caret)
setwd("~/BI & DM Files Etc/Coursera - Data Science/Machine Learning")
pml.trn<-read.csv("pml-training.csv")
pml.trn<-pml.trn[pml.trn$new_window=="no",]
pml.trn<-pml.trn[,colSums(is.na(pml.trn)) != nrow(pml.trn)]
pml.trn<-pml.trn[,colSums(pml.trn!="") != 0]
pml.trn<-pml.trn[,8:60]
nrow(pml.trn); ncol(pml.trn);
```

Below the same row and column processing is applied to the test data.

```{r}
pml.tst<-read.csv("pml-testing.csv")
pml.tst<-pml.tst[pml.tst$new_window=="no",]
pml.tst<-pml.tst[,colSums(is.na(pml.tst)) != nrow(pml.tst)]
pml.tst<-pml.tst[,colSums(pml.tst!="") != 0]
pml.tst<-pml.tst[,8:60]
nrow(pml.tst); ncol(pml.tst)
```

Additionally, highly correlated predictors are removed from both the training and test sets after testing to find that accuracy is relatively unaffected by doing so.

```{r}
rem.col<-findCorrelation(cor(pml.trn[,1:52]),.8)
pml.trn<-pml.trn[,-rem.col]
pml.tst<-pml.tst[,-rem.col]
nrow(pml.trn); ncol(pml.trn)
nrow(pml.tst); ncol(pml.tst)
```

Two models were initially attempted, k-nearest neighbor and random forest, and both provided similarly accurate results. The results of random forest were used here as this model reports out-of-bag error. The final model is reported.

Cross validation is used through the trainControl feature providing 10-fold cross-validation and the reported "out-of-bag" (OOB) error estimate is reported to be .56%.

```{r}
tc<-trainControl(method="cv");
modFit<-train(classe~.,"rf",data=pml.trn, trControl=tc)
modFit
modFit$finalModel
```

And lastly, predictions are made on the provided test data and submitted for grading resulting in 100% correct results.

```{r}
predict(modFit,pml.tst)
```
